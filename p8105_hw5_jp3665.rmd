---
title: "p8105_hw5_jp3665"
author: "Joana Petrescu"
date: "11/18/2020"
output: github_document
---

```{r message=FALSE, warning=FALSE}

library(tidyverse)
#install.packages("rvest")
library(rvest)
library(httr)
library(magrittr)
#insstall.packages("gridExtra")
library(gridExtra)

```


## Washington Post homicide data

This data gathered by the Washington Post contains information about the victim, location, and disposition of over 52,000 homicides that occurred over the past decade in 50 of the largest cities in the U.S.

### Clean Washington Post homicide data

Make data frame of total and unsolved homicides in each city.

```{r}

homicide_data <- read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")

homicide_data <- homicide_data %>%
  mutate(.keep = "all", city_state = paste(city, state, sep = ", "))

head(homicide_data)

homicide_total <- homicide_data %>%
  group_by(city_state) %>%
  summarize(n_homicides = n())

homicide_unsolved <- homicide_data %>%
  filter(disposition != "Closed by arrest") %>%
  group_by(city_state) %>%
  summarize(n_unsolved = n())

homicide_summary <- merge(homicide_total, homicide_unsolved, by = "city_state", all = TRUE) %>% na.omit

homicide_summary

```

### Proportion of homicides that are unsolved test case

Estimate proportion of unsolved homicides for Baltimore, MD as a test case.

```{r}

baltimore_homicide <- homicide_summary %>%
  filter(city_state == "Baltimore, MD") 

baltimore_test <- prop.test(baltimore_homicide$n_unsolved, baltimore_homicide$n_homicides) %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high)

baltimore_test

```

### Iterate over every city in Washington Post data

Estimate proportion of unsolved homicides for each city in Washington Post homicide data set.

```{r}

homicide_input <- homicide_summary %>% remove_rownames() %>% column_to_rownames(var="city_state")

homicide_test <- map2(homicide_input$n_unsolved, homicide_input$n_homicides, prop.test)

homicide_test <- map(homicide_test, broom::tidy)

homicide_test <- map_dfr(homicide_test, extract, c("estimate", "conf.low", "conf.high"))

homicide_test <- homicide_test %>% 
  mutate(city_state = homicide_summary$city_state, estimate, conf.low, conf.high) %>%
  select(city_state, estimate, conf.low, conf.high)

homicide_test

```

```{r}

homicide_test %>% mutate(city_state = fct_reorder(city_state, desc(estimate))) %>% ggplot(aes(x = city_state, y = estimate)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90)) +
  geom_point() +
  ggtitle("Proportion of Unsolved Homicides by City") +
  xlab("City, State") +
  ylab("Proportion of Unsolved Homicides")

```

## Longitudinal experimental data

This data is collected from a longitudinal study with control and experimental subjects.

### Import and tidy data 

Import individual data files, combine into data frame, add sample ID and experimental/control arm columns.

```{r}

con_urls <- str_c("./data/con_0", 01:9, ".csv", sep = "")

con_df <- bind_rows(map(con_urls, read_csv), read_csv("./data/con_10.csv")) %>% mutate(subject_id = str_c("con_", row_number())) %>% mutate(arm = "control")

exp_urls <- str_c("./data/exp_0", 1:9, ".csv", sep = "")

exp_df <- bind_rows(map(exp_urls, read_csv), read_csv("./data/exp_10.csv")) %>% mutate(subject_id = str_c("exp_", row_number())) %>% mutate(arm = "experimental")

con_exp_df <- rbind(con_df, exp_df) %>% select(subject_id, arm, week_1:week_8)

colnames(con_exp_df) = c("subject_id", "arm", "1", "2", "3", "4", "5", "6", "7", "8")

con_exp_df <- con_exp_df %>% gather(key = week, value = observation, 3:10)

con_exp_df

```

### Plot observations for each subject over time

Make spaghetti plot of subject data over time.

```{r}

con_exp_df %>% ggplot(aes(x = week, y = observation, group = subject_id, color = arm)) +
  geom_line() +
  ggtitle("Observed Values for Control and Experimental Subjects Over Time") +
  xlab("Week Number") +
  ylab("Observed Value") +
  theme(legend.title = element_blank())

```

This plot demonstrates that the observations for subjects in the experimental arm of the trial increase during the duration of the study and are generally higher than the observations for subjects in the control arm.


## Power simulation

Simulate different sample sizes and effect sizes in a one-sample t-test in order to study statistical power.

### Generate 5000 datasets for one-sample t-test on normal distribution

Sample size = 30
Standard deviation = 5
Mean = 0

```{r}

sim_function <- function(n, mu, sigma) {
  
  sim_data <-  tibble(
    x = rnorm(n, mean = mu, sd = sigma)
  )
  
  sim_data %>% 
    t.test() %>%
    broom::tidy() %>%
    select(estimate, p.value)
  
}

sim_results_zero <- rerun(5000, sim_function(30, 0, 5)) %>%
  bind_rows %>%
  mutate(mean_est = estimate, p_value = p.value, mu = 0, .keep = "none")

```

### Generate simulated datasets for different mean values

Mean = {1:6}

```{r}

sim_loop = vector("list", length = 6)

for (i in 1:6) {
  
  sim_loop[[i]] <- rerun(5000, sim_function(30, i, 5)) %>%
  bind_rows %>%
  mutate(mean_est = estimate, p_value = p.value, mu = i, .keep = "none")
  
}

sim_loop <- bind_rows(sim_loop)

sim_loop <- rbind(sim_loop, sim_results_zero)

```

### Plot proportion null rejected for each mean

Plot proportion of times that the null hypothesis was rejected (p < 0.05) for each mean

```{r}

prop_reject <- sim_loop %>%
  mutate(reject = as.logical(p_value < 0.05)) %>%
  group_by(mu) %>%
  count(reject = (reject == TRUE)) %>%
  filter(reject == TRUE) %>%
  mutate(prop = n/5000)

prop_reject %>% ggplot(aes(x = mu, y = prop)) +
  geom_bar(stat = "identity", fill="steelblue") +
  theme_minimal() +
  ggtitle("Proportion of times null hypothesis is rejected") +
  xlab("Mu") +
  ylab("Proportion")


```
The null hypothesis was reject more frequently with higher mu values, approaching 100% of the time with mu = 6. 

### Estimated mean vs. mu

Is the sample average of estimated mu across tests for which the null is rejected approximately equal to the true value of mu? 

```{r}

p1 <- sim_loop %>%
  mutate(reject = as.logical(p_value < 0.05)) %>%
  group_by(mu) %>%
  summarize(avg_mean = mean(mean_est)) %>%
  ggplot(aes(x = mu, y = avg_mean)) +
  geom_bar(stat = "identity", fill="steelblue") +
  theme_minimal() +
  ggtitle("Average estimated mean vs. mu, all") +
  xlab("Mu") +
  ylab("Average estimated mean")+
  geom_text(aes(label = round(avg_mean, digits = 2)))


p2 <- sim_loop %>%
  mutate(reject = as.logical(p_value < 0.05)) %>%
  group_by(mu) %>%
  filter(reject == TRUE) %>%
  summarize(avg_mean = mean(mean_est)) %>%
  ggplot(aes(x = mu, y = avg_mean)) +
  geom_bar(stat = "identity", fill="steelblue") +
  theme_minimal() +
  ggtitle("Average estimated mean vs. mu, null hypothesis rejected") +
  xlab("Mu") +
  ylab("Average estimated mean") +
  geom_text(aes(label = round(avg_mean, digits = 2)))


grid.arrange(p1, p2, ncol = 1, nrow = 2)


```
The average estimated mu across datasets for which the null hypothesis was rejected is not approximately equal to mu because rejecting the null hypothesis requires that the distribution be unlikely (< 0.05) to be drawn from a normal distribution with the given parameters (mu, standard deviation) which, by definition, means that he average estimated mu for datasets for which the null hypothesis was rejected will differ from the defined mu value.
